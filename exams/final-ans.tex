\documentclass[10pt]{article}

\usepackage{mathtools, amssymb, bm}
\usepackage{microtype}
\usepackage[utf8]{inputenc}
\usepackage[margin = 0.75in]{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{tikzsymbols}
\usepackage[hidelinks]{hyperref}
\usepackage{titlesec}



\titleformat{\section}{\normalsize\bfseries}{\thesection}{1em}{}
% \titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\setcounter{secnumdepth}{0}
% \numberwithin{equation}{section}

\definecolor{colabcol}{HTML}{960018}
\newcommand{\mycolab}[1]{\textcolor{colabcol}{\textsl{Collaborators:}} #1 \\ }
\newcommand{\mycolaba}[1]{\textcolor{colabcol}{\textsl{Collaborators:}} #1}

\title{
    {\Large Final Exam}
}
\author{
    {\normalsize Aiden Kenny}\\
    {\normalsize STAT GR5205: Linear Regression Models}\\
    {\normalsize Columbia University}
}
\date{\normalsize December 21, 2020}

\begin{document}

\maketitle

% \newcommand{\rx}{\mathcal{X}}
\newcommand{\rx}{X}
% \newcommand{\ry}{\mathcal{Y}}
\newcommand{\ry}{Y}
% \newcommand{\rz}{\mathcal{Z}}
\newcommand{\rz}{Z}
\newcommand{\E}{\mathbb{E}}
% \newcommand{\E}{\mathrm{E}}

%' ============================================================================================================================================================
\section{Question 1} \noindent
Let \(\ry\) denote per-capita gross metropolitan product (GMP), in dollars per person per year, and \(\rx\) denote population, in people. 
The realized values of these random variables are respectively given by the \(n\)-vectors \(\mathbf{y}\) and \(\mathbf{x}\), where \(n = 366\).
\begin{enumerate}
    \item The predictor variable is given by \(\rz \coloneqq \log_{10}\rx\), and the response is \(\ry\). We can see that the population is being transformed 
    by taking the logarithm (with base 10). 
    \item Our estimated model is given by 
    \begin{align}
        % \hat{\ry}
        \E(\ry \,|\, x)
        % \mathbb{E}[\ry \,|\, \rx]
        % = -23306 + 10246 \rz
        = -23306 + 10246 \log_{10} x.
    \end{align}
    \item We have \(\E(\ry \,|\, 1,000,000) = 38170\) and \(\E(\ry \,|\, 200,000) = 31008.35\).
    These answers make sense, a city with a larger population will have a higher GMP per-capita. \\[0.5em]
    \texttt{-23306 + 10246 * log(c(1000000, 200000), 10)}
    \item We cannot give an estimate of \(\E(\ry \,|\, 0)\) because \(\log_{10} 0\) is undefined.
    \item A \(95\%\) confidence interval for \(\beta_1\), denoted as \(\mathcal{I}_{\beta_1}\), is
    \begin{align}
        \mathcal{I}_{\beta_1}
        = \left( \hat{\beta}_1 - t \cdot \mathrm{se}(\hat{\beta}_1), \hat{\beta}_1 + t \cdot \mathrm{se}(\hat{\beta}_1) \right)
        = \big( 10246 - 1.967 \cdot 900, 10246 + 1.967 \cdot 900 \big)
        = \big( 8475.7, 12016.3 \big).
    \end{align}
    The values \(\hat{\beta}_1 = 10246\) and \(\mathrm{se}(\hat{\beta}_1) = 900\) can be found in the \texttt{R} output, and the value 
    \(t = T_{364}^{-1}(0.975) = 1.967\) can be found using the \texttt{qt()} function in \texttt{R}. \\[0.5em]
    \texttt{qt(0.975, 364)}\\[0.5em]
    \texttt{10246 + 1.967 * 900 * c(-1, 1)}
    \item From the \texttt{\#{}\#{}Residual standard error} section, we have \(\hat{\sigma}^2 = 7930^2/364 = 172760.7\). \\[0.5em]
    % \texttt{7930\textasciicircum{}2}
    % \texttt{(7930 / 364)\textasciicircum{}2}
    \texttt{7930\textasciicircum{}2 / 364}
    \item You cannot find the sample variance of \(\rx\) from the \texttt{R} output. We are never considering the value of 
    \(\mathrm{Var}(\rz)\) when constructing the model because we are never treating \(\rz\) as a random variable. We instead are treating it as 
    a set of fixed values \(\mathbf{z}\), either observed before or after the model's design is chosen. When we estimate \(\sigma^2\) in 
    the linear model, we are estimating \(\mathrm{Var}(\epsilon)\), the residuals of the model. And since we cannot make any inferences about 
    \(\mathrm{Var}(\rz)\), we cannot make any inferences about \(\mathrm{Var}(\rx)\) either. 
    % ; practically \(\mathbf{z}\) is either the observed values of the transformed predictor variable before fitting the model, 
    % or the conditional values of the random variable \(\ry \,|\, \mathbf{z}\). 
    \item There are multiple components of the \texttt{R} output that test the hypothesis \(H_0 : \beta_1 = 0\) against \(H_A : \beta_1 \neq 0\). 
    Remember, the output is testing the hypothesis that \(\ry\) and \(\rz\) have a linear relationship, \textsl{not} \(\ry\) and \(\rx\). 
    There are two tests that \texttt{R} runs when using the \texttt{lm()} function: the \(t\) test and the ANOVA test. The \(p\)-palue for the \(t\) test
    is found in the right-most column, \texttt{Pr(>|t|)}, of the \texttt{\#{}\#{}Coefficients} section, and is given by \texttt{<2e-16}. 
    The \(p\)-value for the ANVOA test is found in the last entry in the output, in the \texttt{\#{}\#{}F-statistic} section, and is also given by \texttt{<2e-16}
    (\texttt{R} will estimate the value if it is too small). In both cases, we reject \(H_0\), and it seems that there is indeed a linear relationship 
    between \(\ry\) and \(\rz\) (\(=\log_{10}\rx\)). 
\end{enumerate}

%' ============================================================================================================================================================
\newcommand{\mx}{\mathbf{X}}
\newcommand{\ax}{\widetilde{\mathbf{X}}}
\section{Question 2} \noindent
Suppose we have observed \(n\) observations of \(p\) predictors, given by \(\mathbf{x}_1, \ldots, \mathbf{x}_p\), and an observed response \(\mathbf{y}\).
Let \(\mathbf{X} \coloneqq \begin{bmatrix}
    \mathbf{x}_1 \cdots \mathbf{x}_p
\end{bmatrix}\) be a matrix where the \(j\)th column is \(\mathbf{x}_j\).
Here we also assume that the data has been centered, so each predictor and the response has a mean of zero (this is common to do before fitting a model).
We fit a regression model \(\mathbf{y} = \mathbf{X}\bm{\beta} + \bm{\epsilon}\), and our estimated coefficients are given by 
\(\hat{\bm{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}\). 

% Now, suppose we have \(n\) observations of a new predictor \(\mathbf{x}_{p+1}\)
Now, suppose we have \(n\) observations of a new predictor \(\mathbf{z}\), which was not used at all when determining \(\hat{\bm{\beta}}\). 
It turns out that this new predictor is orthogonal to each of the previous \(p\) predictors, i.e. \(\mathbf{x}_j^T\mathbf{z} = 0\) for all \(j\), 
and so \(\mathbf{X}^T\mathbf{z} = \mathbf{0}\). If we want to fit a new linear model that includes \(\mathbf{z}\), we can use an alternate 
matrix \(\ax \coloneqq \begin{bmatrix}
    \mathbf{X} & \mathbf{z}
\end{bmatrix}\) and fit the model \(\mathbf{y} = \ax \bm{\beta}\); our estimated coefficient will be given by \(\hat{\bm{\beta}} = (\ax^T\ax)^{-1}\ax\mathbf{y}\).
As we will soon see, the estimated coefficients for the original \(p\) predictors is exactly the same as they were in the origianl model (denoted as \(\hat{\bm{\beta}}_0\)), 
and the estimated coefficient for \(\mathbf{z}\) would be the same if a model was fit using \textsl{only} this new predictor!
The key reason for both of these results is that the new predictor is orthogonal to each of the previous ones. 
To see this, we first observe that 
\begin{align*}
    \ax^T\ax
    = \begin{bmatrix}
        \mathbf{X}^T \\ \mathbf{z}^T
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{X} & \mathbf{x}
    \end{bmatrix}
    = \begin{bmatrix}
        \mathbf{X}^T\mathbf{X} & \mathbf{X}^T\mathbf{z} \\
        \mathbf{z}^T \mathbf{X} & \mathbf{z}^T\mathbf{z}
    \end{bmatrix}
    = \begin{bmatrix}
        \mathbf{X}^T\mathbf{X} & \mathbf{0} \\
        \mathbf{0}^T & \mathbf{z}^T\mathbf{z}
    \end{bmatrix}.
\end{align*}
Using the formula for matrix inversion for block matrices (see \href{https://en.wikipedia.org/wiki/Block_matrix#Block_matrix_inversion}{\texttt{here}}), we have 
\begin{align*}
    (\ax^T\ax)^{-1}
    = \begin{bmatrix}
        \mathbf{X}^T\mathbf{X} & \mathbf{0} \\
        \mathbf{0}^T & 1 / \mathbf{z}^T\mathbf{z}
    \end{bmatrix},
\end{align*}
and so the estimated coefficients are given by 
\begin{align}
    \hat{\bm{\beta}}
    = (\ax^T\ax)^{-1}\ax\mathbf{y}
    = \begin{bmatrix}
        \mathbf{X}^T\mathbf{X} & \mathbf{0} \\
        \mathbf{0}^T & 1 / \mathbf{z}^T\mathbf{z}
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{X}^T \\ \mathbf{z}^T
    \end{bmatrix}
    \mathbf{y}
    = \begin{bmatrix}
        (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y} \\
        \mathbf{z}^T\mathbf{y} / \mathbf{z}^T\mathbf{z}
    \end{bmatrix}
    = \left( \hat{\bm{\beta}}_0, \frac{\mathbf{z}^T\mathbf{y}}{\mathbf{z}^T\mathbf{z}} \right)^T.
\end{align}
This result says that the first \(p\) estimated coefficients are given by \(\hat{\bm{\beta}}_0\), while the new predictor's estimated coefficient is 
given by the value \(\mathbf{z}^T\mathbf{y} / \mathbf{z}^T\mathbf{z}\). If we fit a simple linear model using only the new predictor, 
\(\mathbf{y} = \beta \mathbf{z}\), the estimated coefficient is given by 
\(\hat{\beta} = (\mathbf{z}^T\mathbf{z})^{-1}\mathbf{z}^T\mathbf{y} = \mathbf{z}^T\mathbf{y} / \mathbf{z}^T\mathbf{z}\).

The two main points of this question are that adding an orthogonal variable to a linear model does not change the value of the estimated coefficients 
of the previous variables, and obtaining the estimated coefficient for the new variable is as easy as computing two inner products. 
In fact, these two ideas are a possible method for estimating \(\bm{\beta}\) for any linear model. One would first have to orthogonalize each of the 
variables to be used, and the estimated coefficient for the \(j\)th variable is then given by \(\mathbf{x}_j^T\mathbf{y} / \mathbf{x}_j^T\mathbf{x}_j\)
(see chapter 3 of \href{https://web.stanford.edu/~hastie/ElemStatLearn/}{\texttt{this book}} for more info).

%' ============================================================================================================================================================
\section{Question 3} \noindent
\begin{enumerate}
    \item Leave-one-out cross-validation (LOOCV) is a resampling method used to better estimate the effectiveness of a statistical model. 
    We want to see how effective a model is at making predictions on data points not present when the model is being fit. Instead of having to 
    collect a separate data set, we remove a single observation from the data set, fit the model with the remaining data, and then determine the error for 
    that single point. Doing this for each point and taking the average of each error gives us our estiamted test error. 
    The idea of \(k\)-fold cross-validation (KCV) is similar, instead of leaving out one data point, we leave out \(n / k\) data points, and repeat the procedure
    \(k\) times to estimate the test error. In fact, LOOCV is a special case of KCV when \(k = n\). When the number of samples is large, it is more feasible to 
    use KCV (usually with \(k = 5\) or \(k = 10\)) instead of LOOCV, since it is computationally faster and has a smaller variance. 
    \item Since we are fitting a linear model \(n\) times, there will be \(n\) matrix inversions to compute.
\end{enumerate}

%' ============================================================================================================================================================
\newcommand{\rn}{N}
\section{Question 4} \noindent
Let \(\ry\) and \(\rn\) denote a city's GMP in dollars and population, respectively (we are not treating \(\rn\) as a random variable), and suppose we observe 
\(\ry = c \rn^{r - 1} \mathrm{exp}(\epsilon)\), where \(\epsilon \sim \mathrm{N}(0, \sigma^2)\). Here \(c\) is a scaling factor and \(r\) is the scaling exponent. 
If \(r > 1\) then the city has supra-linear scaling, if \(r = 1\) then the city has linear scaling, and if \(r < 1\) then the city has sub-linear scaling. 
\begin{enumerate}
    \item We cannot fit a linear model of \(\ry\) with respect to \(\rn\), since \(\ry\) is not linear with respect to the model parameters. We can, however,
    take the logarithm of both sides to get 
    \begin{align}
        \log \ry
        = \log c + (r - 1) \log \rn + \epsilon,
    \end{align}
    and can now regress \(\ry\) on \(\log\rn\), since it is linear with respect to the new parameters \(\beta_0 = \log c\) and \(\beta_1 = r - 1\).
    \item If our estimated coefficients are given by \(\hat{\beta}_0\) and \(\hat{\beta}_1\), then the origianl parameters can be estimated by 
    \(\hat{c} = \mathrm{exp}(\hat{\beta}_0)\) and \(\hat{r} = \hat{\beta}_1 + 1\). 
    \item If we have a \(95\%{}\) confidence interval for \(\beta_0\) given by \(\beta_0 \in (-2.31, 4.16)\), the corresponding confidence interval for \(c\) would be 
    \(c \in \big( \mathrm{e}^{-2.31}, \mathrm{e}^{4.16} \big) = (0.0993, 64.072)\). \\[0.5em]
    \texttt{exp(c(-2.31, 4.16))}
    \item To test whether or not a city has \textsl{either} supra-linear scaling \textsl{or} sub-linear scaling, we want to determine whether or not \(r = 1\). 
    To do this, we could use the information from our linear model and test \(H_0 : \beta_1 = 0\) against \(H_A : \beta_1 \neq 0\). If there is significant evidence to 
    reject \(H_0\), then we would conclude that the city does not have linear scaling. 
    \item Using \(n = 12\) observations, we have \(\hat{\beta}_1 = 0.36\) and \(\mathrm{se}(\hat{\beta}_1) = 0.2\), and so our corresponding \(t\) statistic is 
    \(\mathcal{T} = \hat{\beta}_1 / \mathrm{se}(\hat{\beta}_1) = 0.36 / 0.2 = 1.8\). The critical value of this \(t\) test is 
    \(k = T_{10}^{-1}(0.975) = 2.228\). Because \(\mathcal{T} < k\) and \(\mathcal{T} > -k\), we fail to reject \(H_0\). The data indicates that this city has 
    linear scaling. 
\end{enumerate}

%' ============================================================================================================================================================
\section{Question 5} \noindent


%' ============================================================================================================================================================
\section{Question 6} \noindent
Suppose we have the linear relationship \(\bm{\ry} = \mathbf{X}\bm{\beta} + \bm{\epsilon}\), where \(\epsilon \sim \mathrm{N}(\mathbf{0}, \sigma^2 \mathbf{I})\), 
and there are a maximum of \(k\) variables that can be used from \(\mathbf{X}\). We would like to infer how many variables to include in our model. 
Let \(f_p(\mathbf{X})\) denote the linear model that is fit using \(p\) predictors. 
\begin{enumerate}
    \item For a given number of predictors \(p\), Mallows \(C_p\) is given by 
    \begin{align*}
        C_p
        = \frac{\| \mathbf{y} - f_p(\mathbf{X}) \|^2}{\hat{\sigma^2}} + 2p - n
        = (n - k)\frac{\| \mathbf{y} - f_p(\mathbf{X}) \|^2}{\| \mathbf{y} - f_k(\mathbf{X}) \|^2} + 2p - n.
    \end{align*}
    That is, the value of \(\hat{\sigma}^2\) is the mean-squared error for the model fit with all \(k\) predictors. 
    Intuitively, for different values of \(p\) we will get a different value of \(C_p\); the value of \(\| \mathbf{y} - f_p(\mathbf{X}) \|^2\) will change 
    for each value of \(p\), and we also have \(C_p\) increase by 2 for each additional variable considered. 
    We choose the value of \(p\) that gives us the lowest \(C_p\), and then use some kind of selection criteria (e.g. stepwise selection or the lasso) 
    to determine \textsl{which} of the \(p\) predictors we should use. 
    \item The idea behind using AIC and BIC for model selection is the same as Mallows \(C_p\), with the exeption of using a different formula. For AIC and BIC,
    we need to assume that the errors are normally distributed (as we have). For \(p = 1, \ldots, k\), we find the value of \(\mathrm{AIC}(p)\) and \(\mathrm{BIC}(p)\)
    and choose the \(p\) that gives us the lowest criteria. 
    \item While similar in concept, AIC and BIC have fundamentally different derivations, which result in different formulas to use for the criteria 
    and different tendencies for model selection. The formulas for each are given by 
    \begin{align*}
        \mathrm{AIC}(p)
        = 2p - 2 \max(\ell;p)
        ~~\text{and}~~
        \mathrm{BIC}(p)
        = p \log n - 2 \max(\ell;p);
    \end{align*}
    here \(\max(\ell;p)\) is the maximum possible value of the log-likelihood for the model with \(p\) predictors
    There are many more sophisticated justifications to using one or the other (that I was unable to wrap my head around), but practically, AIC is 
    better to use if you are interested in model \textsl{prediction}, while BIC is better to use if you are interested in model \textsl{inference}. 
    Also, BIC tends to choose smaller models than AIC or Mallows \(C_p\).
    \item Consider the new selection criteria \(\mathrm{D} = 2 \| \hat{\bm{\beta}} \|_1 - 2 \max(\ell;p)\). Compared to AIC, we see that both criteria give the 
    same weight to \(\max(\ell;p)\). The difference lies in how the coefficients play a role; by replacing \(p\) with \(\|\hat{\bm{\beta}}\|_1\), we are changing 
    the nature of the critetia. Whereas AIC would increase as the \textsl{number of parameters} increased, \(\mathrm{D}\) will increase as the 
    \textsl{total magnitute of each of the parameters} increases. 
    \item The nature of the criteria \(\mathrm{D}\) suggests that it is much more similar to the lasso, which chooses the model parameters 
    by penalizing large estimated coefficients. Indeed, the loss function for the lasso with \(p\) predictors is 
    \begin{align*}
        P(\bm{\beta};\lambda)
        = \| \mathbf{y} - \mathbf{X}\bm{\beta} \|^2 + \lambda \| \bm{\beta} \|_1,
    \end{align*}
    which also incorperates the \(1\)-norm. 
\end{enumerate}

\end{document}